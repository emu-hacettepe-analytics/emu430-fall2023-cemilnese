[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Term Project",
    "section": "",
    "text": "Here you can see summary of our course project. You can also follow our studies through Team_Safe_Istanbul project page.\nSummary\nWe will utilize three datasets provided by the Istanbul Metropolitan Municipality.\nThe first dataset, titled “Earthquake Scenario Analysis Results”, contains the outcomes of analyses conducted based on a 7.5 Mw nighttime earthquake scenario.\nThe second dataset, “Neighborhood-Based Building Numbers in 2017”, comprises information on the number of buildings in Istanbul’s neighborhoods. These buildings are categorized by their construction year and the number of floors.\nThe third dataset is “Municipality Population in 2019”, contains population of Istanbul by districts in 2019.\nOur objective is to compile a comprehensive report and identify the districts in Istanbul that are most susceptible to potential earthquakes. We aim to create an ordered priority list for neighborhoods and develop a risk map for Istanbul, taking geographical coordinates into account.\n\n\n\n&gt;&lt;\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello! My name is Cemil Neşe.\nThis is my personal webpage.\nLet’s discover together what is up in Data Science World.\nPlease fasten your seatbelts.\n\n\n\n&gt;&lt;\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Analysis of Turkish Movies (IMBD)\nMovies are filtered and URL’s are saved\n\n\nCode\n# searches between  01/01/2010-31/12/2023\nurl_1 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250\" \n\n# searches before 31/12/2009\nurl_2 &lt;- \"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\"\n\ncombined_url &lt;- c(url_1, url_2)\n\n\nNecessary packages are imported\n\nCode\nknitr::opts_chunk$set(warning = FALSE)\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\nWeb-Scrapping\nTurkish movies with have minimum 2500 vote are filtered.\n\n\nCode\ntitle &lt;- c()\nrelease_year &lt;- c()\nduration &lt;- c()\nrating &lt;- c()\nvote &lt;- c()\nfor (url in combined_url) {\n  Html &lt;- read_html(url)\n  \n  title_names &lt;- Html |&gt; html_nodes('.ipc-title__text')\n  title_names &lt;- html_text(title_names)\n  title_names &lt;- tail(head(title_names,-1),-1)\n  title_names &lt;- str_split(title_names, \" \", n=2)\n  title_names &lt;- unlist(lapply(title_names, function(x) {x[2]}))\n  title &lt;- append(title,title_names)\n  \n  years &lt;- Html |&gt; html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata')\n  years &lt;- html_text(years)\n  years &lt;- unlist(lapply(years, function(years){\n           strtrim(years, 4)}))\n  release_year &lt;- append(release_year, as.numeric(years))\n  \n  durations &lt;- Html |&gt; html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata')\n  durations &lt;- html_text(durations)\n  durations &lt;- unlist(lapply(durations, function(durations){\n           str_extract(durations, \"\\\\d+h( \\\\d+m)?|\\\\d+m|\\\\d+\") |&gt; str_extract(\"(?&lt;=^.{4}).*\")}))\n  convert_to_minutes &lt;- function(duration) {\n  hours &lt;- as.numeric(str_extract(duration, \"\\\\d+(?=h)\"))\n  minutes &lt;- as.numeric(str_extract(duration, \"\\\\d+(?=m)\"))\n  total_minutes &lt;- ifelse(is.na(hours),0, hours) * 60 + ifelse(is.na(minutes), 0, minutes)\n  return(total_minutes)\n}\n  durations &lt;- unlist(lapply(durations, convert_to_minutes))\n  duration  &lt;- append(duration, durations)\n  \n  ratings &lt;- Html |&gt; html_nodes(\".sc-43986a27-1.fVmjht\")\n  ratings &lt;- html_text(ratings)\n  ratings &lt;- unlist(lapply(ratings, function(ratings){\n    str_sub(ratings, 1, 3)\n  }))\n  rating &lt;- append(rating, as.numeric(ratings))\n  \n  votes &lt;- Html |&gt; html_nodes(\".sc-53c98e73-0.kRnqtn\")\n  votes &lt;- html_text(votes)\n  extract_numeric &lt;- function(string) {\n  numeric_part &lt;- str_extract(string, \"\\\\d[0-9,]+\")\n  numeric_value &lt;- as.numeric(gsub(\",\", \"\", numeric_part))\n  return(numeric_value)\n}\n  votes &lt;- unlist(lapply(votes, extract_numeric))\n  vote  &lt;- append(vote, votes)\n}\nmovies  &lt;- data.frame(title, release_year, duration, rating,vote)\n\nhead(movies)\n\n\n                     title release_year duration rating  vote\n1        Kuru Otlar Üstüne         2023      197    8.1  5058\n2  Istanbul Için Son Çagri         2023       91    5.3  7329\n3 Yedinci Kogustaki Mucize         2019      132    8.2 54151\n4           Ölümlü Dünya 2         2023      117    7.5  3440\n5                   Bihter         2023      113    3.6  3340\n6             Ölümlü Dünya         2018      107    7.6 30258\n\n\nAbove, you can see the dataframe generated by scrapping the data from web.\na) Arranged by Rating\npre-processing\n\n\nCode\nmovies &lt;- movies %&gt;% \n  arrange(desc(rating)) %&gt;%\n  mutate(ranking = c(1: length(title))) %&gt;%\n  select(ranking, everything())\n\n\nHead\nTop 5 movies based on user ratings are shown below.\n\n\nCode\nhead(movies, n = 5L) %&gt;% select(title, rating, vote, release_year)\n\n\n                         title rating  vote release_year\n1               Hababam Sinifi    9.2 42511         1975\n2       CM101MMXI Fundamentals    9.1 46995         2013\n3                   Tosun Pasa    8.9 24327         1976\n4 Hababam Sinifi Sinifta Kaldi    8.9 24369         1975\n5                Süt Kardesler    8.8 20884         1976\n\n\nI don’t think there is someone haven’t watched one of these movies yet. I guess everybody would agree upon these 5. There are many great actors/actresses that make us laugh even today. The second one is actually not a movie though.\nTail\nThe bottom 5 is shown below.\n\n\nCode\ntail(movies, n = 5L) %&gt;% select(title, rating, vote)\n\n\n                             title rating  vote\n466                 Cumali Ceber 2    1.2 10228\n467                          Müjde    1.2  9920\n468              15/07 Safak Vakti    1.2 20606\n469 Cumali Ceber: Allah Seni Alsin    1.0 39266\n470                           Reis    1.0 73972\n\n\nJudging a movie before watching it is not appropriate. So, I have no comments about these movies.\nb) My Favorite Ones\nMy favorite 3 movies, their rankings and ratings are listed below.\n\n\nCode\nmovies %&gt;% \n  filter(title == \"Dag II\" | title == \"A.R.O.G\" | title == \"Kurtlar Vadisi: Gladio\")\n\n\n  ranking                  title release_year duration rating   vote\n1      24                 Dag II         2016      135    8.2 109865\n2     136                A.R.O.G         2008      127    7.3  44631\n3     311 Kurtlar Vadisi: Gladio         2009       97    6.2   5288\n\n\nc) Visualization\nYearly rating averages are visualized below. You can see that rating averages are decreasing as getting closer to today. However, one need consider the number of movies released since it is directly related with the rating averages.\n\n\nCode\nmovies %&gt;% \n  group_by(release_year) %&gt;%\n  summarize(yearly_average = mean(rating)) %&gt;%\n  ggplot(aes(x = release_year, y = yearly_average)) + geom_point() +\n  ggtitle(\"Yearly Rating Averages\") + theme_pander()\n\n\n\n\n\nBelow you can see that number of movies released are generally increased over the years.\n\n\nCode\nmovies %&gt;%\n  group_by(release_year) %&gt;%\n  summarize(movie_number = n()) %&gt;%\n  ggplot(aes(x = release_year, y = movie_number)) + geom_point() + ggtitle(\"Number of Movies Over the Year\") + theme_pander()\n\n\n\n\n\nBox Plot\n\n\nCode\nmovies %&gt;%\n  ggplot(aes(x = as.factor(release_year), y = rating)) +\n  geom_boxplot() +\n  theme_pander() + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1))+ \n  xlab(\"release_year\")\n\n\n\n\n\nAfter 2003 number of movies increased dramatically and results relatively lower ratings.\nVote vs Rating\n\n\nCode\nmovies %&gt;%\n  ggplot(aes(x = vote, rating)) + geom_point() + theme_pander()+\n  ggtitle(\"Vote vs Rating\")\n\n\n\n\n\nMost of the votes within the range of 0 and 15000. In this range there is accumulation above 5.0 rating. As the number of votes increases rating is generally high. However further investigation with larger dataset is required.\nDuration vs Rating\n\n\nCode\nmovies %&gt;%\n  ggplot(aes(x = duration, rating)) + geom_point() + theme_pander()+\n  ggtitle(\"Duration vs Rating\")\n\n\n\n\n\nDuration of the movies are accumulated between roughly 75-130 minutes. However in this range we can see both high and low ratings. Hence, there is not clear relationship between duration and rating.\nTurkish Movies in IMDB Top 1000\nWeb-Scrapping\n\n\nCode\nknitr::opts_chunk$set(warning = FALSE)\n\nurl &lt;- \"https://m.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR\"\n\nHtml_ &lt;- read_html(url)\n\ntitle_top &lt;- Html_ |&gt; html_nodes('.ipc-title__text')\ntitle_top &lt;- html_text(title_top)\ntitle_top &lt;- tail(head(title_top,-1),-1)\ntitle_top &lt;- str_split(title_top, \" \", n=2)\ntitle_top &lt;- unlist(lapply(title_top, function(x) {x[2]}))\n\n\nrelease_year_top &lt;- c()\nrelease_years &lt;- Html_ |&gt; html_nodes(\".sc-43986a27-7.dBkaPT.dli-title-metadata\")\nrelease_years &lt;- html_text(release_years)\nrelease_years  &lt;- unlist(lapply(release_years, function(release_years){\n           strtrim(release_years, 4)}))\nrelease_year_top &lt;- append(release_year_top, as.numeric(release_years))\n                          \nmovies_top &lt;- data_frame(title_top, release_year_top)\n\n\nJoining with the original table\n\n\nCode\nleft_join(movies_top, movies, by = c(\"title_top\" = \"title\")) %&gt;%\n  select(-release_year_top) %&gt;% select(ranking, everything()) %&gt;%\n  arrange(desc(rating))\n\n\n# A tibble: 11 × 6\n   ranking title_top                 release_year duration rating  vote\n     &lt;int&gt; &lt;chr&gt;                            &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1      20 Ayla: The Daughter of War         2017      125    8.3 42989\n 2      23 Yedinci Kogustaki Mucize          2019      132    8.2 54151\n 3      27 Babam ve Oglum                    2005      108    8.2 91021\n 4      31 Eskiya                            1996      128    8.1 71698\n 5      32 Her Sey Çok Güzel Olacak          1998      107    8.1 27119\n 6      37 Kis Uykusu                        2014      196    8   54631\n 7      40 Nefes: Vatan Sagolsun             2009      128    8   35015\n 8      38 Ahlat Agaci                       2018      188    8   26995\n 9      42 G.O.R.A.                          2004      127    8   66027\n10      44 Vizontele                         2001      110    8   38398\n11      58 Bir Zamanlar Anadolu'da           2011      157    7.8 49348\n\n\nThe ranking shows the actual place of these movies in the movies dataset. Although they are in the top 1000 list of IMDB, they are not at the top of first dataframe. Hence, we can say that IMDB has some other parameters to order the movies in its top 1000 lists. These parameters can be awards they took, tickets sold etc.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hello, I’m Cemil Neşe, a fourth-year industrial engineering student with a passion for statistics and data science. Currently, I’m gaining practical experience as a Junior Officer at Turkish Airlines. My academic background in industrial engineering equips me with problem-solving skills and a strong analytical mindset, while my interest in statistics and data science drives me to explore and apply data-driven solutions. I’m enthusiastic about leveraging data to optimize processes, improve decision-making, and enhance operational efficiency within the airline and defense industries. With a blend of academic knowledge and real-world experience, I’m dedicated to making a positive impact by harnessing the power of data.\nYou can download my cv here."
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nTurkish Airlines, Junior Catering and Inflight Operations Control Officer / PT, SEP 2023 - Present"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nTurkish Aerospace, Sky Discover Summer Intern, JUL 2023 - JUL 2023\nŞişecam, First Step Summer Intern, AUG 2023 - AUG 2023"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignments I conducted for the Fall 2023 EMU 430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on November 11, 2023\n\n\n\n&gt;&lt;\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Stay tuned for updates :)\n\n\n\n&gt;&lt;\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "(c)",
    "text": "(c)\nContent of na_example:\n\nlibrary(dslabs)\ndata(na_example)\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\nTotal number of NAs:\n\npaste(\"Total number of NAs in na_example is\",sum(is.na(na_example)))\n\n[1] \"Total number of NAs in na_example is 145\"\n\n\nReplaced NAs with 0:\n\nna_example[is.na(na_example)] &lt;- 0\nnew_data_set &lt;- na_example \nnew_data_set\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 0 2 2 1 4 0 1 1 2 1 2 2 1 2 5 0 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 0 0 0 1 1 5 1 3 1 0 4 4 7 3 2 0 0 1 0 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 0 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 0 4 3 4 3 1 2 1 0 0 0 0 1 5 1 2 1 3 5 3 2 2 0 0 0 0 3 5 3 1 1 4\n [149] 2 4 3 3 0 2 3 2 6 0 1 1 2 2 1 3 1 1 5 0 0 2 4 0 2 5 1 4 3 3 0 4 3 1 4 1 1\n [186] 3 1 1 0 0 3 5 2 2 2 3 1 2 2 3 2 1 0 2 0 1 0 0 2 1 1 0 3 0 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 0 5 1 4 0 3 0 0 1 1 5 2 3 3 2 4 0 3 2 5 0 2 3\n [260] 4 6 2 2 2 0 2 0 2 0 3 3 2 2 4 3 1 4 2 0 2 4 0 6 2 3 1 0 2 2 0 1 1 3 2 3 3\n [297] 1 0 1 4 2 1 1 3 2 1 2 3 1 0 2 3 3 2 1 2 3 5 5 1 2 3 3 1 0 0 1 2 4 0 2 1 1\n [334] 1 3 2 1 1 3 4 0 1 2 1 1 3 3 0 1 1 3 5 3 2 3 4 1 4 3 1 0 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 0 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 0 3 3 0 2 0 1 2 1 1 4 2 1 4 4 0\n [408] 1 2 0 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 0 4 4 4 1 1 0 4\n [445] 3 0 1 3 1 3 2 4 2 2 2 3 2 1 4 3 0 1 4 3 1 3 2 0 3 0 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 0 3 2 1 1 2 0 2 2 2 3 3 1 1 2 0 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 0 1 4 1 2 4 1 3 2 0 1 1 0 2 1 1 4 2 3 3 1 5 3 1 1 2 0 1 1\n [556] 3 1 3 2 4 0 2 3 2 1 2 1 1 1 2 2 3 1 5 2 0 2 0 3 2 2 2 1 5 3 2 3 1 0 3 1 2\n [593] 2 2 1 2 2 4 0 6 1 2 0 1 1 2 2 3 0 3 2 3 3 4 2 0 2 0 4 0 1 1 2 2 3 1 1 1 3\n [630] 0 2 5 0 7 1 0 4 3 3 1 0 1 1 1 1 3 2 4 2 2 3 0 0 1 4 3 2 2 2 3 2 4 2 2 4 0\n [667] 0 0 6 3 3 1 4 4 2 1 0 1 6 0 3 3 2 1 1 6 0 1 5 1 0 2 6 2 0 4 1 3 1 2 0 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 0 1 2 2 2 2 4 5 0 0 0 4 3 3 3\n [741] 2 4 2 4 0 0 0 0 2 1 0 2 4 3 2 0 2 3 1 3 4 0 1 2 1 2 0 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 0 0 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 0 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 0 1 3 1 2 0 1 2 1 2 1 0 1 3 2 3 2 0 2 1 4 2 0 0 0 2 4 2 0 0 3\n [852] 1 0 5 5 2 2 2 0 2 1 3 1 3 2 4 2 4 0 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 0 3\n [889] 3 2 2 0 0 3 2 1 2 4 1 1 1 1 4 3 2 0 3 2 0 1 0 3 2 1 1 1 2 0 2 2 3 3 2 0 0\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 0 1 1 1 0 4 3 5 1 1 2 0 2 2 2 2 5 2 2 3 1 2 3 0\n [963] 1 2 0 0 2 0 3 1 1 2 5 3 5 1 1 4 0 2 1 3 1 1 2 4 3 3 3 0 1 1 2 2 1 1 2 2 0\n[1000] 2\n\n\nTotal number of NAs in new_data_set:\n\npaste(\"Total number of NAs in new data frame is\", sum(is.na(new_data_set)))\n\n[1] \"Total number of NAs in new data frame is 0\""
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "(a)",
    "text": "(a)"
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "(b)",
    "text": "(b)"
  },
  {
    "objectID": "about.html#employments",
    "href": "about.html#employments",
    "title": "About Me",
    "section": "Employments",
    "text": "Employments\n\nTurkish Airlines, Junior Catering and Inflight Operations Control Officer / PT, SEP 2023 - Present"
  }
]